{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATASET_PATH = \"E:/Brain Station 23/Human Action Recognition/UCF101/UCF-101\"  # Path to UCF101 dataset\n",
    "FRAMES_PATH = \"extracted_frames\"  # Path to save extracted frames\n",
    "PROCESSED_DATA_PATH = \"processed_data\"  # Path to save processed ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21.5M/21.5M [03:49<00:00, 98.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "#Initialize YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')  # You can use other variants like yolov8n, yolov8m, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(data), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Run Preprocessing\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m X, y \u001b[38;5;241m=\u001b[39m prepare_temporal_data(\u001b[43mDATASET_PATH\u001b[49m)\n\u001b[0;32m     65\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, X)  \u001b[38;5;66;03m# Save sequences\u001b[39;00m\n\u001b[0;32m     66\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, y)  \u001b[38;5;66;03m# Save labels\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATASET_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to extract frames from videos\n",
    "def extract_frames(video_path, output_dir, frame_rate=10):\n",
    "    \"\"\"Extract frames from a video at a fixed frame rate.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    success, frame = video.read()\n",
    "    while success:\n",
    "        if frame_count % frame_rate == 0:\n",
    "            frame_file = os.path.join(output_dir, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(frame_file, frame)\n",
    "        frame_count += 1\n",
    "        success, frame = video.read()\n",
    "    video.release()\n",
    "\n",
    "# Function to detect humans and crop ROIs using YOLOv8\n",
    "def detect_humans_yolo_v8(yolo_model, frames_path, output_dir):\n",
    "    \"\"\"Detect humans in frames using YOLOv8 and save cropped ROIs.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for frame_file in tqdm(os.listdir(frames_path)):\n",
    "        frame_path = os.path.join(frames_path, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        results = yolo_model.predict(frame, conf=0.5)  # Run YOLO detection\n",
    "        for i, bbox in enumerate(results[0].boxes.xyxy.cpu().numpy()):\n",
    "            cls = int(results[0].boxes.cls[i])\n",
    "            conf = results[0].boxes.conf[i]\n",
    "            if cls == 0 and conf > 0.5:  # Class 0: Human\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "                roi = frame[y1:y2, x1:x2]\n",
    "                roi_path = os.path.join(output_dir, f\"roi_{i}_{frame_file}\")\n",
    "                cv2.imwrite(roi_path, roi)\n",
    "\n",
    "# Function to prepare temporal sequences\n",
    "def prepare_temporal_data(dataset_path, sequence_length=16):\n",
    "    \"\"\"Prepare sequences of ROIs for temporal model training.\"\"\"\n",
    "    data, labels = [], []\n",
    "    for action_class in os.listdir(dataset_path):\n",
    "        action_path = os.path.join(dataset_path, action_class)\n",
    "        if not os.path.isdir(action_path):\n",
    "            continue\n",
    "        for video_file in os.listdir(action_path):\n",
    "            video_path = os.path.join(action_path, video_file)\n",
    "            video_frames_path = os.path.join(FRAMES_PATH, action_class, video_file.split('.')[0])\n",
    "            rois_path = os.path.join(PROCESSED_DATA_PATH, action_class, video_file.split('.')[0])\n",
    "\n",
    "            # Extract frames and detect humans\n",
    "            extract_frames(video_path, video_frames_path)\n",
    "            detect_humans_yolo_v8(model, video_frames_path, rois_path)\n",
    "\n",
    "            # Create sequences\n",
    "            rois = sorted(os.listdir(rois_path))  # Sort to maintain temporal order\n",
    "            for i in range(0, len(rois) - sequence_length, sequence_length):\n",
    "                sequence = []\n",
    "                for j in range(sequence_length):\n",
    "                    roi_path = os.path.join(rois_path, rois[i + j])\n",
    "                    roi = cv2.imread(roi_path)\n",
    "                    roi = cv2.resize(roi, (224, 224)) / 255.0  # Normalize ROI\n",
    "                    sequence.append(roi)\n",
    "                data.append(np.array(sequence))\n",
    "                labels.append(action_class)  # Label is the folder name\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Run Preprocessing\n",
    "X, y = prepare_temporal_data(DATASET_PATH)\n",
    "np.save(\"X.npy\", X)  # Save sequences\n",
    "np.save(\"y.npy\", y)  # Save labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
