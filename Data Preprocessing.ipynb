{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and actions\n",
    "data_path = \"action_data\"  # Main directory for data\n",
    "actions = ['Fighting', 'Yoga', 'Walking']  # Actions to collect data for\n",
    "required_sequences = 15  # Expected number of sequences per action\n",
    "sequence_length = 30  # Length of each sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Media Pipe Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe setup\n",
    "mp_holistic = mp.solutions.h11111olistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    # Pose landmarks (including legs)\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 3)\n",
    "    \n",
    "    # Left hand landmarks\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    \n",
    "    # Right hand landmarks\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    \n",
    "    # Left leg landmarks (indices 23-25 in Mediapipe)\n",
    "    left_leg = np.array([[res.x, res.y, res.z] for res in [results.pose_landmarks.landmark[i] for i in [23, 25, 27, 29, 31]]]).flatten() if results.pose_landmarks else np.zeros(5 * 3)\n",
    "    \n",
    "    # Right leg landmarks (indices 24-26 in Mediapipe)\n",
    "    right_leg = np.array([[res.x, res.y, res.z] for res in [results.pose_landmarks.landmark[i] for i in [24, 26, 28, 30, 32]]]).flatten() if results.pose_landmarks else np.zeros(5 * 3)\n",
    "    \n",
    "    # Concatenate all landmarks\n",
    "    return np.concatenate([pose, lh, rh, left_leg, right_leg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data verification and collection...\n",
      "Action 'Fighting': 15/15 sequences available.\n",
      "Action 'Yoga': 0/15 sequences available.\n",
      "Collecting sequence 1 for 'Yoga'...\n",
      "Sequence 1 saved.\n",
      "Collecting sequence 2 for 'Yoga'...\n",
      "Sequence 2 saved.\n",
      "Collecting sequence 3 for 'Yoga'...\n",
      "Sequence 3 saved.\n",
      "Collecting sequence 4 for 'Yoga'...\n",
      "Sequence 4 saved.\n",
      "Collecting sequence 5 for 'Yoga'...\n",
      "Sequence 5 saved.\n",
      "Collecting sequence 6 for 'Yoga'...\n",
      "Sequence 6 saved.\n",
      "Collecting sequence 7 for 'Yoga'...\n",
      "Sequence 7 saved.\n",
      "Collecting sequence 8 for 'Yoga'...\n",
      "Sequence 8 saved.\n",
      "Collecting sequence 9 for 'Yoga'...\n",
      "Sequence 9 saved.\n",
      "Collecting sequence 10 for 'Yoga'...\n",
      "Sequence 10 saved.\n",
      "Collecting sequence 11 for 'Yoga'...\n",
      "Sequence 11 saved.\n",
      "Collecting sequence 12 for 'Yoga'...\n",
      "Sequence 12 saved.\n",
      "Collecting sequence 13 for 'Yoga'...\n",
      "Sequence 13 saved.\n",
      "Collecting sequence 14 for 'Yoga'...\n",
      "Sequence 14 saved.\n",
      "Collecting sequence 15 for 'Yoga'...\n",
      "Sequence 15 saved.\n",
      "Action 'Walking': 0/15 sequences available.\n",
      "Collecting sequence 1 for 'Walking'...\n",
      "Sequence 1 saved.\n",
      "Collecting sequence 2 for 'Walking'...\n",
      "Sequence 2 saved.\n",
      "Collecting sequence 3 for 'Walking'...\n",
      "Sequence 3 saved.\n",
      "Collecting sequence 4 for 'Walking'...\n",
      "Sequence 4 saved.\n",
      "Collecting sequence 5 for 'Walking'...\n",
      "Sequence 5 saved.\n",
      "Collecting sequence 6 for 'Walking'...\n",
      "Sequence 6 saved.\n",
      "Collecting sequence 7 for 'Walking'...\n",
      "Sequence 7 saved.\n",
      "Collecting sequence 8 for 'Walking'...\n",
      "Sequence 8 saved.\n",
      "Collecting sequence 9 for 'Walking'...\n",
      "Sequence 9 saved.\n",
      "Collecting sequence 10 for 'Walking'...\n",
      "Sequence 10 saved.\n",
      "Collecting sequence 11 for 'Walking'...\n",
      "Sequence 11 saved.\n",
      "Collecting sequence 12 for 'Walking'...\n",
      "Sequence 12 saved.\n",
      "Collecting sequence 13 for 'Walking'...\n",
      "Sequence 13 saved.\n",
      "Collecting sequence 14 for 'Walking'...\n",
      "Sequence 14 saved.\n",
      "Collecting sequence 15 for 'Walking'...\n",
      "Sequence 15 saved.\n",
      "All resources released. Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Initialize resources\n",
    "cap = None\n",
    "holistic = None\n",
    "\n",
    "try:\n",
    "    # Initialize the Video Capture for live webcam\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default camera\n",
    "\n",
    "    # Set camera resolution to 1080p\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)  # Set width to 1920 pixels\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)  # Set height to 1080 pixels\n",
    "\n",
    "    # Initialize Mediapipe Holistic model\n",
    "    holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    print(\"Starting data verification and collection...\")\n",
    "\n",
    "    for action in actions:\n",
    "        folder_path = os.path.join(data_path, action)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # Count existing sequences\n",
    "        existing_files = [file for file in os.listdir(folder_path) if file.endswith('.npy')]\n",
    "        num_files = len(existing_files)\n",
    "        print(f\"Action '{action}': {num_files}/{required_sequences} sequences available.\")\n",
    "\n",
    "        # Collect missing sequences\n",
    "        if num_files < required_sequences:\n",
    "            for sequence_num in range(num_files, required_sequences):\n",
    "                print(f\"Collecting sequence {sequence_num + 1} for '{action}'...\")\n",
    "                sequence = []\n",
    "\n",
    "                while len(sequence) < sequence_length:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"Camera error. Exiting...\")\n",
    "                        raise RuntimeError(\"Failed to read from camera.\")\n",
    "\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    results = holistic.process(frame_rgb)\n",
    "\n",
    "                    # Draw landmarks\n",
    "                    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "                    mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                    mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Display progress information on the frame\n",
    "                    cv2.putText(frame, f\"Action: {action}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Sequence: {sequence_num + 1}/{required_sequences}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Frames: {len(sequence)}/{sequence_length}\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                    # Show the frame\n",
    "                    cv2.imshow(\"Data Collection\", frame)\n",
    "\n",
    "                    # Append keypoints\n",
    "                    keypoints = extract_keypoints(results)\n",
    "                    sequence.append(keypoints)\n",
    "\n",
    "                    # Exit on 'q' key\n",
    "                    if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                        print(\"Data collection interrupted by user.\")\n",
    "                        raise KeyboardInterrupt  # Trigger safe exit\n",
    "\n",
    "                # Save the sequence\n",
    "                np.save(os.path.join(folder_path, f\"{sequence_num}.npy\"), sequence)\n",
    "                print(f\"Sequence {sequence_num + 1} saved.\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nOperation stopped by user.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Ensure resources are released\n",
    "    if cap:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if holistic:\n",
    "        holistic.close()\n",
    "    print(\"All resources released. Exiting...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape verification complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "for action in actions:\n",
    "    folder_path = os.path.join(data_path, action)\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = np.load(file_path)\n",
    "        if data.shape != (sequence_length, 255):  # Update 255 to match your feature size\n",
    "            print(f\"Inconsistent shape in {file_path}: {data.shape}\")\n",
    "print(\"Shape verification complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed sequence lengths.\n"
     ]
    }
   ],
   "source": [
    "def fix_sequence_length(data, target_length=30):\n",
    "    if len(data) > target_length:\n",
    "        return data[:target_length]  # Truncate\n",
    "    elif len(data) < target_length:\n",
    "        padding = np.zeros((target_length - len(data), data.shape[1]))  # Pad with zeros\n",
    "        return np.vstack((data, padding))  # Append padding\n",
    "    return data\n",
    "\n",
    "for action in actions:\n",
    "    folder_path = os.path.join(data_path, action)\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = np.load(file_path)\n",
    "        fixed_data = fix_sequence_length(data, target_length=sequence_length)\n",
    "        np.save(file_path, fixed_data)  # Overwrite with fixed sequence\n",
    "print(\"Fixed sequence lengths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (31, 30, 255), Validation set: (7, 30, 255), Test set: (7, 30, 255)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X, y = [], []\n",
    "for action in actions:\n",
    "    for file in os.listdir(os.path.join(data_path, action)):\n",
    "        data = np.load(os.path.join(data_path, action, file))  # Load the .npy file\n",
    "        X.append(data)\n",
    "        y.append(label_map[action])  # Map action label to numeric value\n",
    "\n",
    "X = np.array(X)\n",
    "y = to_categorical(y).astype(int)  # Convert labels to one-hot encoding\n",
    "\n",
    "# First split: Train (70%) and Temp (30% for validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: Validation (15%) and Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check the sizes of the splits\n",
    "print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitted Folder Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved successfully in the folder: data_splits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Specify the folder to save the datasets\n",
    "save_folder = \"data_splits\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Save datasets to the specified folder\n",
    "np.save(os.path.join(save_folder, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(save_folder, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(save_folder, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(save_folder, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(save_folder, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(save_folder, \"y_test.npy\"), y_test)\n",
    "\n",
    "print(f\"Datasets saved successfully in the folder: {save_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
